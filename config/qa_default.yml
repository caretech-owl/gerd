model: &qa_model
  name: "mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF"
  file: "meta-llama-3.1-8b-instruct-abliterated.Q6_K.gguf"
  temperature: 0.01
  max_new_tokens: 128
  context_length: 512
  prompt_config:
    text: "Du bist ein hilfreicher Assistent.\nBitte beantworte die Frage: '{question}' basierend auf dem folgenden Kontext:\n{context}\nGib nur die hilfreiche Antwort unten zurück und nichts anderes. Halte dich außerdem sehr kurz mit der Antwort und antworte nur in Stichworten."
features:
  analyze:
    model:
      <<: *qa_model
      context_length: 4096
      prompt_config:
        path: "prompts/qa_analyze.txt"
  analyze_mult_prompts:
    model:
      <<: *qa_model
      prompt_config:
        path: "prompts/qa.txt"
  return_source: true
embedding:
  chunk_size: 256
  chunk_overlap: 25
  vector_count: 2
  model:
    # name: "sentence-transformers/distiluse-base-multilingual-cased-v1"
    name: "sentence-transformers/all-MiniLM-L6-v2"
  #db_path: "vectorstore/db_faiss"
  db_path: ""
