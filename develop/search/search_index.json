{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Generating and evaluating relevant documentation","text":"<p>GERD is developed as an experimental library to investigate how large language models (LLMs) can be used to generate and analyze (sets of) documents.</p> <p>This project was initially forked from Llama-2-Open-Source-LLM-CPU-Inference  by Kenneth Leung.</p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>If you just want to it try out, you can clone the project and install dependencies with <code>pip</code>:</p> <pre><code>git clone https://github.com/caretech-owl/gerd.git\ncd gerd\npip install -e \".[full]\"\npython examples/hello.py\n</code></pre> Source: examples/hello.py <pre><code>import logging\n\nfrom gerd.config import load_gen_config\nfrom gerd.gen.chat_service import ChatService\nfrom gerd.models.model import PromptConfig\n\nlogging.basicConfig(level=logging.WARNING)\nlogging.getLogger(\"gerd\").setLevel(logging.DEBUG)\n\nlogging.info(\n    \"Loading chat service...\"\n    \" When this is the first time you run this script, it will download the model.\"\n    \" This may take a few minutes.\"\n)\n\nchat = ChatService(load_gen_config(\"hello\"))\nres = chat.submit_user_message({\"word\": \"teleportation\"})\nlogging.info(res)\n\nchat.set_prompt_config(PromptConfig.model_validate({\"text\": \"{message}\"}))\nres = chat.submit_user_message({\"message\": \"Hello! What is one plus one?\"})\nlogging.info(res)\n</code></pre> <p>If you want to try this out in your browser, head over to binder \ud83d\udc49 .  Note that running LLMs on the CPU (and especially on limited virtual machines like binder) takes some time.</p>"},{"location":"#question-and-answer-example","title":"Question and Answer Example","text":"<p>Follow quickstart but execute <code>gradio</code> with the <code>qa_frontend</code> instead of the example file. When the server is done loading, open <code>http://127.0.0.1:7860</code> in your browser.</p> <pre><code>gradio gerd/frontends/qa_frontend.py\n# Some Llama.cpp outut\n# ...\n# * Running on local URL:  http://127.0.0.1:7860\n</code></pre> <p>Click the 'Click to Upload' button and search for a GRASCCO document named <code>Caja.txt</code> which is located in the <code>tests/data/grascoo</code> folder and upload it into the vector store. Next, you can query information from the document. For instance <code>Wie hei\u00dft der Patient?</code> (What is the patient called?).</p> <p></p>"},{"location":"#prompt-chaining","title":"Prompt Chaining","text":"<p>Prompt chaining is a prompt engineering approach to increase the 'reflection' of a large language model onto its given answer. Check <code>examples/chaining.py</code> for an illustration.</p> <pre><code>python examples/chaining.py\n# ...\n====== Resolved prompt =====\n\nsystem: You are a helpful assistant. Please answer the following question in a truthful and brief manner.\nuser: What type of mammal lays the biggest eggs?\n\n# ...\nResult: Based on the given information, the largest egg-laying mammal is the blue whale, which can lay up to 100 million eggs per year. However, the other assertions provided do not align with this information.\n</code></pre> Source: examples/chaining.py <pre><code>import logging\n\nfrom gerd.config import load_gen_config\nfrom gerd.gen.chat_service import ChatService\n\nlogging.basicConfig(level=logging.DEBUG)\n\ngen = ChatService(load_gen_config(\"gen_chaining\"))\nres = gen.generate({\"question\": \"What type of mammal lays the biggest eggs?\"})\nprint(f\"Result: {res.text}\")  # noqa: T201\n</code></pre> Config: config/gen_chaining.yml <pre><code>model:\n  name: \"Qwen/Qwen2.5-0.5B-Instruct\"\n  temperature: 0.05\n  max_new_tokens: 512\n  context_length: 2048\n  prompt_setup:\n    - [\"system\", text: \"You are a helpful assistant. Please answer the following question in a truthful and brief manner.\"]\nfeatures:\n  prompt_chaining:\n    prompts:\n      - text: \"{question}\"\n      - text: \"Here is a statement:\\n{response_1}\\n\\nMake a bullet point list of the assumptions you made when producing the above statement.\\n\\n\"\n      - text: \"Here is a bullet point list of assertions:\\n{response_2}\\n\\nFor each assertion, determine whether it is true or false. If it is false, explain why.\\n\\n\"\n      - text: \"{response_3}\\n\\nIn light of the above facts, how would you answer the question '{question}'\"\n</code></pre> <p>As you see, the answer does not make much sense with the default model which is rather small. Give it a try with meta-llama/Llama-3.2-3B. To use this model, you need to login with the huggingface cli and accept the Meta Community License Agreement.</p>"},{"location":"#full-documentation","title":"Full Documentation","text":"<p>A more detailled documentation can be found here \ud83d\udc49 .</p>"},{"location":"#used-tools","title":"Used Tools","text":"<ul> <li>LangChain: Framework for developing applications powered by language models</li> <li>C Transformers: Python bindings for the Transformer models implemented in C/C++ using GGML library</li> <li>FAISS: Open-source library for efficient similarity search and clustering of dense vectors.</li> <li>Sentence-Transformers (all-MiniLM-L6-v2): Open-source pre-trained transformer model for embedding text to a 384-dimensional dense vector space for tasks like</li> <li>Poetry: Tool for dependency management and Python packaging</li> </ul>"},{"location":"#files-and-content","title":"Files and Content","text":"<ul> <li><code>/assets</code>: Images relevant to the project</li> <li><code>/config</code>: Configuration files for LLM applications</li> <li><code>/examples</code>: Examples that demonstrate the different usage scenarios</li> <li><code>/gerd</code>: Code related to <code>GERD</code></li> <li><code>/images</code>: Images for the documentation</li> <li><code>/models</code>: Binary file of GGML quantized LLM model (i.e., Llama-2-7B-Chat)</li> <li><code>/prompts</code>: Plain text prompt files</li> <li><code>/templates</code>: Prompt files as jinja2 templates </li> <li><code>/tests</code>: Unit tests for <code>GERD</code></li> <li><code>/vectorstore</code>: FAISS vector store for documents</li> <li><code>pyproject.toml</code>: TOML file to specify which versions of the dependencies used (Poetry)</li> </ul>"},{"location":"#references","title":"References","text":"<ul> <li>https://github.com/kennethleungty/Llama-2-Open-Source-LLM-CPU-Inference</li> <li>https://pubmed.ncbi.nlm.nih.gov/36073490</li> <li>https://huggingface.co</li> </ul>"},{"location":"concepts/","title":"Concepts","text":"<p>GERD is primarly a tool for prototyping workflows for working with Large Language Models. It is meant to act as 'glue' between different tools and services and should ease the access to these tools.</p> <p>In general, there should be only be two components involved in a GERD workflow: A configuration and a service. The configuration can be assembled from different sources and should be able to be used in different services. The foundation of such a configration is a YAML file. GERD provides a set of those which can be found in the <code>config</code> directory. Configurations in this directly can be accessed by name as shown in the following example. A simple configutation file may look like this:</p> <pre><code>model:\n  name: \"Qwen/Qwen2.5-0.5B-Instruct\"\n  temperature: 0.1\n  top_p: 0.90\n  max_new_tokens: 256\n  repetition_penalty: 1.1\n  prompt_setup:\n    - [system, text: \"You are a helpful assistant. Start your answers with 'Sure thing, buddy!'.\"]\n  prompt_config:\n    text: \"Please say the word '{word}' three times.\"\n</code></pre> <p>And can be used with a <code>ChatService</code> via <code>load_gen_config</code> shown in the following example:</p> <pre><code>import logging\n\nfrom gerd.config import load_gen_config\nfrom gerd.gen.chat_service import ChatService\nfrom gerd.models.model import PromptConfig\n\nlogging.basicConfig(level=logging.WARNING)\nlogging.getLogger(\"gerd\").setLevel(logging.DEBUG)\n\nlogging.info(\n    \"Loading chat service...\"\n    \" When this is the first time you run this script, it will download the model.\"\n    \" This may take a few minutes.\"\n)\n\nchat = ChatService(load_gen_config(\"hello\"))\nres = chat.submit_user_message({\"word\": \"teleportation\"})\nlogging.info(res)\n\nchat.set_prompt_config(PromptConfig.model_validate({\"text\": \"{message}\"}))\nres = chat.submit_user_message({\"message\": \"Hello! What is one plus one?\"})\nlogging.info(res)\n</code></pre>"},{"location":"develop/","title":"Development Guide","text":""},{"location":"develop/#basics","title":"Basics","text":"<p>To get started on development you need to install uv. You can use <code>pip</code>, <code>pipx</code> or <code>conda</code> to do so:</p> <pre><code>pip install uv\n</code></pre> <p>Next install the package and all dependencies with <code>uv sync</code>.</p> <pre><code># cd &lt;gerd_project_root&gt;\nuv sync\n</code></pre> <p>After that, it should be possible to run scripts without further issues:</p> <pre><code>uv run examples/hello.py\n</code></pre> <p>To add a new runtime dependency, just run <code>uv add</code>:</p> <pre><code>uv add langchain\n</code></pre> <p>To add a new development dependency, run <code>uv add</code> with the <code>--dev</code> flag:</p> <pre><code>uv add mypy --dev\n</code></pre>"},{"location":"develop/#pre-commit-hooks-recommended","title":"Pre-commit hooks (recommended)","text":"<p>Pre-commit hooks are used to check linting and run tests before commit changes to prevent faulty commits. Thus, it is recommended to use these hooks! Hooks should not include long running actions (such as tests) since committing should be fast. To install pre-commit hooks, execute this once:</p> <pre><code>uv run pre-commit install\n</code></pre>"},{"location":"develop/#further-tools","title":"Further tools","text":""},{"location":"develop/#poe-task-runner","title":"Poe Task Runner","text":"<p>Task runner configuration are stored in the <code>pyproject.toml</code> file. You can run most of the tools mentioned above with a (shorter) call to <code>poe</code>.</p> <pre><code>uv run poe lint  # do some linting (with mypy)\n</code></pre>"},{"location":"develop/#pytest","title":"PyTest","text":"<p>Test case are run via pytest. Tests can be found in the <code>/tests</code> folder. Tests will not be run via pre-commit since they might be too complex to be done before commits. To run the standard set of tests use the <code>poe</code> task <code>test</code>:</p> <pre><code>uv run poe test\n</code></pre> <p>More excessive testing can be trigger with <code>test_manual</code> which will NOT mock calls to the used models:</p> <pre><code>uv run poe test_manual\n</code></pre>"},{"location":"develop/#ruff","title":"Ruff","text":"<p>Ruff is used for linting and code formatting. Ruff follows <code>black</code> styling ref. Ruff will be run automatically before commits when pre-commit hooks are installed. To run <code>ruff</code> manually, use uv:</p> <pre><code>uv run ruff check gerd\n</code></pre> <p>There is a VSCode extension that handles formatting and linting.</p>"},{"location":"develop/#mypy","title":"MyPy","text":"<p>MyPy does static type checking. It will not be run automatically. To run MyPy manually use uv with the folder to be checked:</p> <pre><code>uv run mypy gerd\n</code></pre>"},{"location":"develop/#implemented-guis","title":"Implemented GUIs","text":""},{"location":"develop/#run-frontend","title":"Run Frontend","text":"<p>Either run Generate Frontend:</p> <pre><code>uv run poe gen_dev\n</code></pre> <p>or QA Frontend:</p> <pre><code>uv run poe qa_dev\n</code></pre> <p>or the GERD Router:</p> <pre><code># add _dev for the gradio live reload version\n# omit in 'prod'\nuv run router[_dev]\n</code></pre>"},{"location":"develop/#cicd-and-distribution","title":"CI/CD and Distribution","text":""},{"location":"develop/#github-actions","title":"GitHub Actions","text":"<p>GitHub Actions can be found under .github/workflows. There is currently one main CI workflow called <code>python-ci.yml</code>:</p> <pre><code># This workflow will install Python dependencies, run tests and lint with a variety of Python versions\n# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions\n\nname: Linting/Testing Python\n\non:\n  push:\n    branches: [main, dev-gha]\n  pull_request:\n    branches: [main]\n\njobs:\n  linting:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install uv\n        run: pipx install uv\n      - name: Set up Python 3.12\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.12\"\n      - name: Install development dependencies with extras\n        run: uv sync\n      - name: Run ruff linting via pre-commit on all files and verbose\n        uses: pre-commit/action@v3.0.0\n        with:\n          extra_args: ruff --all-files -v\n      - name: Run linting\n        run: uv run poe lint\n  testing:\n    needs: linting\n    strategy:\n      matrix:\n        os: [ubuntu-latest, windows-latest]\n        python-version: [\"3.12\", \"3.10\"]\n    runs-on: ${{ matrix.os }}\n    steps:\n      - uses: actions/checkout@4\n      - name: Cache HuggingFace models and data\n        uses: actions/cache@v4\n        with:\n          path: ~/.cache/huggingface\n          key: ${{ runner.os }}-hf\n      - name: Install uv\n        run: pipx install uv\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Install development dependencies with extras\n        run: uv sync\n      - name: Run tests\n        run: uv run poe test\n    # - name: Upload coverage to Codecov\n    #   uses: codecov/codecov-action@v3\n    #   with:\n    #     env_vars: OS,PYTHON\n    #     fail_ci_if_error: true\n    #     files: ./coverage.xml\n    #     name: codecov-umbrella\n    #     verbose: true\n</code></pre> <p>In its current config it will only be executed when a PR for <code>main</code> is created or when a special <code>dev-gha</code> branch is created. It will also trigger actions when commits are pushed to <code>main</code> directly but this should be avoided.</p>"},{"location":"develop/#github-issue-templates","title":"GitHub Issue Templates","text":"<p>This project uses GitHub issue templates. Currently, there are three templates available.</p>"},{"location":"develop/#bug-report","title":"Bug Report","text":"<pre><code>name: Bug\ndescription: File a bug report\ntitle: \"[Bug]: \"\nlabels: [\"bug\"]\n# assignees:\n#   - aleneum\nbody:\n  - type: markdown\n    attributes:\n      value: |\n        Thanks for taking the time to fill out this bug report!\n  - type: textarea\n    id: expected-behavior\n    attributes:\n      label: Expected Behavior\n      description: What should happen\n    validations:\n      required: true\n  - type: textarea\n    id: actual-behavior\n    attributes:\n      label: Actual Behavior\n      description: What happened instead\n    validations:\n      required: true\n  - type: textarea\n    id: steps-reproduce\n    attributes:\n      label: Steps to Reproduce the Problem\n      value: |\n        1.\n        2.\n        3.\n\n    validations:\n      required: true\n  - type: input\n    id: affected-version\n    attributes:\n      label: Affected version\n      description: Version number or commit hash\n      placeholder: \"0.1.0\"\n    validations:\n      required: true\n  - type: dropdown\n    id: affected-components\n    attributes:\n      label: Affected components\n      description: Which components are affected\n      multiple: true\n      options:\n        - Gen Service\n        - Qa Service\n        - Frontend\n        - Backend\n    validations:\n      required: false\n  - type: dropdown\n    id: affected-plattforms\n    attributes:\n      label: Affected plattforms\n      description: Which plattforms are affected\n      multiple: true\n      options:\n        - Windows\n        - Linux\n        - MacOS\n    validations:\n      required: false\n  - type: textarea\n    id: further-information\n    attributes:\n      label: Further contextual information and suggestions\n      description: More detailed descriptions or possible solutions\n    validations:\n      required: false\n</code></pre>"},{"location":"develop/#feature-request","title":"Feature Request","text":"<pre><code>name: Feature Request\ndescription: Suggest an idea for this project\ntitle: \"[FR]: \"\nlabels: [\"enhancement\"]\n# assignees:\n#   - aleneum\nbody:\n  - type: markdown\n    attributes:\n      value: Do you have an idea for a feature that would make this project more helpful or easier to use?\n  - type: textarea\n    id: problem-description\n    attributes:\n      label: Problem description\n      description: Is your feature request related to a problem? Please describe.\n    validations:\n      required: true\n  - type: textarea\n    id: solution\n    attributes:\n      label: Solution\n      description: A clear and concise description of what you want to happen.\n    validations:\n      required: true\n  - type: textarea\n    id: additional-context\n    attributes:\n      label: Additional context\n      description: Add any other context or screenshots about the feature request here.\n    validations:\n      required: false\n  - type: dropdown\n    id: affected-components\n    attributes:\n      label: Affected components\n      description: Which components are affected\n      multiple: true\n      options:\n        - Gen Service\n        - Qa Service\n        - Frontend\n        - Backend\n    validations:\n      required: false\n</code></pre>"},{"location":"develop/#use-case","title":"Use Case","text":"<pre><code>name: Use Case\ndescription: A description of a user-centered system requirement\ntitle: \"[UC]: \"\nlabels: [\"use case\"]\n# assignees:\n#   - aleneum\nbody:\n  - type: textarea\n    id: summary\n    attributes:\n      label: Summary\n      description: A concise description of the use case\n    validations:\n      required: true\n  - type: textarea\n    id: rationale\n    attributes:\n      label: Rationale\n      description: The motivation and value added by the described use case\n    validations:\n      required: true\n  - type: dropdown\n    id: level\n    attributes:\n      label: Level\n      multiple: false\n      options:\n        - user goal\n        - subfunction\n  - type: input\n    id: actors\n    attributes:\n      label: Actors\n      description: Someone or something with behavior, e.g. a person (identified by role), a computer system, or an organization\n    validations:\n      required: true\n  - type: textarea\n    id: preconditions\n    attributes:\n      label: Preconditions\n      description: What needs to be true on start\n      placeholder: |\n        - Use Cases: #1, #2\n        - User is authenticated\n    validations:\n      required: true\n  - type: textarea\n    id: postconditions\n    attributes:\n      label: Postconditions\n      description: What must be true on successful completion\n      placeholder: \"The form \"\n    validations:\n      required: true\n  - type: textarea\n    id: basic-flow\n    attributes:\n      label: Basic Flow\n      description: A typical, unconditional happy path\n      value: |\n        1.\n        2.\n        3.\n\n    validations:\n      required: true\n  - type: textarea\n    id: alternative-paths\n    attributes:\n      label: Alternative Paths\n      description: Alternate scenarios of success or failure\n      placeholder: |\n        2.1\n        2.2\n        3.1\n\n    validations:\n      required: false\n  - type: textarea\n    id: visualisation\n    attributes:\n      label: Visualisation\n      description: A mermaid diagram or image depiciting the action flow\n      value: |\n        ```mermaid\n        flowchart LR;\n          1--&gt;2\n          2--&gt;3\n          3--&gt;4\n          3--&gt;3.1\n          3.1--&gt;3.2\n          3.2--&gt;2\n          4--&gt;4.1\n          4.1--&gt;4\n        ```\n    validations:\n      required: false\n  - type: textarea\n    id: related-issues\n    attributes:\n      label: Other related issues, use cases, features\n      description: What must be true on successful completion\n      placeholder: \"#1 #2 #3\"\n    validations:\n      required: false\n</code></pre>"}]}